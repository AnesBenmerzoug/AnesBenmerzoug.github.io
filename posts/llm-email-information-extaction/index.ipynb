{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "date: 2024-11-25\n",
    "title: \"Using an LLM for information extraction\"\n",
    "keywords: [\n",
    "    \"Enron email dataset\",\n",
    "    \"Information extraction\",\n",
    "    \"LLM\",\n",
    "    \"NLP\",\n",
    "    \"llama.cpp\"\n",
    "]\n",
    "license: \"CC BY\"\n",
    "execute: \n",
    "  cache: true\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post we will see how to use a local LLM to extract structured information from emails.\n",
    "\n",
    "My very first project when I started working at appliedAI Initiative in 2021, involved information extraction from emails for a company that makes a document management system. Back then LLMs were not yet as widespread and as useful as they are right now, so we decided to train a model from scratch. We however didn't have any labelled data for training because we couldn't use their customer data due to privacy reasons and had to resort to manually labelling emails from the [Enron email dataset]() and in the end the results were not very impressive.\n",
    "\n",
    "Now, this type of application is simpler than ever and I want to demonstrate that in this blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "from email.message import EmailMessage\n",
    "from email.parser import Parser\n",
    "from email.policy import default\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from deepdiff import DeepDiff\n",
    "from llama_cpp import Llama\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, filename: str | os.PathLike, chunk_size: int = 1024) -> None:\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total = int(response.headers.get(\"content-length\", 0))\n",
    "    filename = Path(filename)\n",
    "    with filename.open(\"wb\") as file, tqdm(\n",
    "        desc=filename.name,\n",
    "        total=total,\n",
    "        unit=\"iB\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in response.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_email_to_dict(email: EmailMessage) -> dict:\n",
    "    email_dict = {\"subject\": email[\"subject\"]}\n",
    "    sender = {\"email\": email[\"from\"].strip()}\n",
    "    if email[\"X-from\"] and email[\"X-from\"] != email[\"from\"]:\n",
    "        sender[\"name\"] = email[\"X-from\"].strip()\n",
    "    email_dict[\"sender\"] = sender\n",
    "\n",
    "    recipients = []\n",
    "    for type_ in [\"to\", \"cc\", \"bcc\"]:\n",
    "        recipient_names = email.get(f\"X-{type_}\", \"\").split(\",\")\n",
    "        recipient_emails = email.get(type_, \"\").split(\",\")\n",
    "        if len(recipient_emails) != len(recipient_names):\n",
    "            recipient_names = [\"\"] * len(recipient_emails)\n",
    "        for recipient_name, recipient_email in zip(recipient_names, recipient_emails):\n",
    "            recipient = {\"type\": type_, \"email\": recipient_email.strip()}\n",
    "            if recipient_name and recipient_name != recipient_email:\n",
    "                recipient[\"name\"] = recipient_name.strip()\n",
    "            recipients.append(recipient)\n",
    "\n",
    "    email_dict[\"recipients\"] = list(sorted(recipients, key=lambda x: x[\"email\"]))\n",
    "\n",
    "    return email_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_extracted_information_accuracy(\n",
    "    extracted_info,\n",
    "    expected_info: dict,\n",
    ") -> float:\n",
    "    diff_result = DeepDiff(\n",
    "        extracted_info,\n",
    "        expected_info,\n",
    "        get_deep_distance=True,\n",
    "        verbose_level=2,\n",
    "        exclude_paths=[\"root['sender']['phone_number']\", \"root['sender']['role']\"],\n",
    "        exclude_regex_paths=[\n",
    "            r\"root\\['recipients'\\]\\[\\d+\\]\\['phone_number'\\]\",\n",
    "            r\"root\\['recipients'\\]\\[\\d+\\]\\['role'\\]\",\n",
    "        ],\n",
    "        ignore_order=True,\n",
    "    )\n",
    "    return 1 - diff_result[\"deep_distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOTAL_EMAILS = 30\n",
    "N_TRAIN_EMAILS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Similarly to my first project, we will use as data emails from the [Enron dataset](https://www.cs.cmu.edu/~enron/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz\"\n",
    "dataset_dir = Path(tempfile.gettempdir()) / \"llm_information_extraction\"\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "dataset_tar_file = dataset_dir / \"enron_mail_20150507.tar.gz\"\n",
    "dataset_extracted_dir = dataset_dir / \"enron_emails\"\n",
    "\n",
    "if not dataset_tar_file.is_file():\n",
    "    download(dataset_url, dataset_tar_file)\n",
    "\n",
    "shutil.rmtree(dataset_extracted_dir, ignore_errors=True)\n",
    "dataset_extracted_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with tarfile.open(dataset_tar_file, \"r:gz\") as tar:\n",
    "    already_visited_person = set()\n",
    "    for i, tarinfo in enumerate(tqdm(tar, desc=\"Tar archive files\")):\n",
    "        if len(already_visited_person) == N_TOTAL_EMAILS:\n",
    "            break\n",
    "        if not tarinfo.isfile():\n",
    "            continue\n",
    "        if \"inbox\" not in tarinfo.name:\n",
    "            continue\n",
    "        person_name = tarinfo.name.split(\"/\")[1]\n",
    "        if person_name in already_visited_person:\n",
    "            continue\n",
    "        already_visited_person.add(person_name)\n",
    "        tar.extract(tarinfo, dataset_extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_files = [x for x in dataset_extracted_dir.rglob(\"*\") if x.is_file()]\n",
    "\n",
    "email_parser = Parser(policy=default)\n",
    "parsed_emails: list[tuple[EmailMessage, dict[str, Any]]] = []\n",
    "\n",
    "for email_file in email_files:\n",
    "    with email_file.open() as f:\n",
    "        parsed_email = email_parser.parse(f)\n",
    "    parsed_email_dict = convert_email_to_dict(parsed_email)\n",
    "    parsed_emails.append((parsed_email, parsed_email_dict))\n",
    "\n",
    "train_set_indices = random.choices(range(0, N_TOTAL_EMAILS), k=N_TRAIN_EMAILS)\n",
    "test_set_indices = list(set(range(0, N_TOTAL_EMAILS)).difference(train_set_indices))\n",
    "train_set = [parsed_emails[i] for i in train_set_indices]\n",
    "test_set = [parsed_emails[i] for i in test_set_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_email, sample_email_dict = train_set[0]\n",
    "print(sample_email.as_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_email_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama.from_pretrained(\n",
    "    \"bartowski/Llama-3.2-1B-Instruct-GGUF\",\n",
    "    filename=\"Llama-3.2-1B-Instruct-Q8_0.gguf\",\n",
    "    n_ctx=16384,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_json_schema = {\n",
    "    \"type\": \"json_object\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"subject\": {\"type\": \"string\"},\n",
    "            \"sender\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"email\": {\"type\": \"string\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"phone_number\": {\"type\": \"string\"},\n",
    "                    \"role\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\"email\"],\n",
    "            },\n",
    "            \"recipients\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": [\n",
    "                    {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"type\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"to\", \"cc\", \"bcc\"],\n",
    "                            },\n",
    "                            \"email\": {\"type\": \"string\"},\n",
    "                            \"name\": {\"type\": \"string\"},\n",
    "                            \"phone_number\": {\"type\": \"string\"},\n",
    "                            \"role\": {\"type\": \"string\"},\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"email\",\n",
    "                            \"type\",\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"subject\", \"sender\", \"recipients\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are a helpful assistant that extract information from a user provided email in JSON format that adheres to the following schema:\n",
    "\n",
    "{json.dumps(email_json_schema, indent=4)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": sample_email.as_string()},\n",
    "    ],\n",
    "    response_format=email_json_schema,\n",
    "    temperature=0.3,\n",
    ")\n",
    "extracted_information = json.loads(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "extracted_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accuracy = compute_extracted_information_accuracy(\n",
    "    extracted_information, sample_email_dict\n",
    ")\n",
    "print(f\"Sample email information extraction accuracy: {sample_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "\n",
    "for parsed_email, parsed_email_dict in tqdm(test_set, desc=\"Emails\"):\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": parsed_email.as_string()},\n",
    "        ],\n",
    "        response_format=email_json_schema,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    extracted_information = json.loads(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "    accuracy = compute_extracted_information_accuracy(\n",
    "        extracted_information, parsed_email_dict\n",
    "    )\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "mean_test_accuracy = np.mean(test_accuracies).item()\n",
    "print(\n",
    "    f\"Mean email information extraction test accuracy: {mean_test_accuracy * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Optimization\n",
    "\n",
    "As we have seen so far, the results are good but not great.\n",
    "\n",
    "We can improve by using a few-shot prompt with some examples from our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "\n",
    "for parsed_email, parsed_email_dict in tqdm(train_set, desc=\"Emails\"):\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": parsed_email.as_string()},\n",
    "        ],\n",
    "        response_format=email_json_schema,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    extracted_information = json.loads(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "    accuracy = compute_extracted_information_accuracy(\n",
    "        extracted_information, parsed_email_dict\n",
    "    )\n",
    "    train_accuracies.append(accuracy)\n",
    "\n",
    "mean_train_accuracy = np.mean(train_accuracies).item()\n",
    "print(\n",
    "    f\"Mean email information extraction train accuracy: {mean_train_accuracy * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_accuracy_index = np.argmin(train_accuracies)\n",
    "worst_accuracy_email = train_set[worst_accuracy_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy_index = np.argmax(train_accuracies)\n",
    "best_accuracy_email = train_set[best_accuracy_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(16)\n",
    "indices = set(range(len(train_set)))\n",
    "indices = list(indices.difference([worst_accuracy_index, best_accuracy_index]))\n",
    "random_index = rng.choice(indices)\n",
    "random_email = train_set[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_with_examples = (\n",
    "    system_prompt\n",
    "    + f\"\"\"\n",
    "\n",
    "Use the following examples as reference:\n",
    "\n",
    "# Example 1\n",
    "## Email\n",
    "{worst_accuracy_email}\n",
    "## Extracted Information\n",
    "{json.dumps(convert_email_to_dict(worst_accuracy_email), indent=4)}\n",
    "\n",
    "# Example 2\n",
    "## Email\n",
    "{best_accuracy_email}\n",
    "## Extracted Information\n",
    "{json.dumps(convert_email_to_dict(best_accuracy_email), indent=4)}\n",
    "\n",
    "# Example 3\n",
    "## Email\n",
    "{random_email}\n",
    "## Extracted Information\n",
    "{json.dumps(convert_email_to_dict(random_email), indent=4)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(system_prompt_with_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "\n",
    "for parsed_email, parsed_email_dict in tqdm(test_set, desc=\"Emails\"):\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt_with_examples,\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": parsed_email.as_string()},\n",
    "        ],\n",
    "        response_format=email_json_schema,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    extracted_information = json.loads(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "    accuracy = compute_extracted_information_accuracy(\n",
    "        extracted_information, parsed_email_dict\n",
    "    )\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "mean_test_accuracy = np.mean(test_accuracies).item()\n",
    "print(\n",
    "    f\"Mean email information extraction test accuracy: {mean_test_accuracy * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this post, we have seen how to use a local LLM, using llama-cpp-python, to extract information from the raw content of emails and how use a few-shot prompt with well chosen examples to improve the results.\n",
    "\n",
    "Manually optimizing the prompt is however in general a tedious and manual process.\n",
    "\n",
    "We could instead use dspy to automatically optimize the prompt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_information_extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

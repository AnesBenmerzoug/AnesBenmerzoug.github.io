{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "date: 2024-11-25\n",
    "title: \"Using an LLM for information extraction\"\n",
    "keywords: [\n",
    "    \"Enron email dataset\",\n",
    "    \"Information extraction\",\n",
    "    \"LLM\",\n",
    "    \"NLP\",\n",
    "    \"llama.cpp\"\n",
    "]\n",
    "license: \"CC BY\"\n",
    "execute: \n",
    "  cache: true\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post we will see how to use a local LLM to extract structured information from emails.\n",
    "\n",
    "My very first project when I started working at appliedAI Initiative in 2021, involved information extraction from emails for a company that makes a document management system. Back then LLMs were not yet as widespread and as useful as they are right now, so we decided to train a model from scratch. We however didn't have any labelled data for training because we couldn't use their customer data due to privacy reasons and had to resort to manually labelling emails from the [Enron email dataset]() and in the end the results were not very impressive.\n",
    "\n",
    "Now, this type of application is simpler than ever and I want to demonstrate that in this blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "from email.message import EmailMessage\n",
    "from email.parser import Parser\n",
    "from email.policy import default\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import dspy\n",
    "import numpy as np\n",
    "import requests\n",
    "from deepdiff import DeepDiff\n",
    "from llama_cpp import Llama\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, filename: str | os.PathLike, chunk_size: int = 1024) -> None:\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total = int(response.headers.get(\"content-length\", 0))\n",
    "    filename = Path(filename)\n",
    "    with filename.open(\"wb\") as file, tqdm(\n",
    "        desc=filename.name,\n",
    "        total=total,\n",
    "        unit=\"iB\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in response.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_email_to_dict(email: EmailMessage) -> dict:\n",
    "    email_dict = {\"subject\": email[\"subject\"]}\n",
    "    sender = {\"email\": email[\"from\"].strip()}\n",
    "    if email[\"X-from\"] and email[\"X-from\"] != email[\"from\"]:\n",
    "        sender[\"name\"] = email[\"X-from\"].strip()\n",
    "    email_dict[\"sender\"] = sender\n",
    "\n",
    "    recipients = []\n",
    "    for type_ in [\"to\", \"cc\", \"bcc\"]:\n",
    "        recipient_names = email.get(f\"X-{type_}\", \"\").split(\",\")\n",
    "        recipient_emails = email.get(type_, \"\").split(\",\")\n",
    "        if len(recipient_emails) != len(recipient_names):\n",
    "            recipient_names = [\"\"] * len(recipient_emails)\n",
    "        for recipient_name, recipient_email in zip(recipient_names, recipient_emails):\n",
    "            recipient = {\"type\": type_, \"email\": recipient_email.strip()}\n",
    "            if recipient_name and recipient_name != recipient_email:\n",
    "                recipient[\"name\"] = recipient_name.strip()\n",
    "            recipients.append(recipient)\n",
    "\n",
    "    email_dict[\"recipients\"] = list(sorted(recipients, key=lambda x: x[\"email\"]))\n",
    "\n",
    "    return email_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_extracted_information_accuracy(\n",
    "    extracted_info,\n",
    "    expected_info: dict,\n",
    ") -> float:\n",
    "    diff_result = DeepDiff(\n",
    "        extracted_info,\n",
    "        expected_info,\n",
    "        get_deep_distance=True,\n",
    "        verbose_level=2,\n",
    "        exclude_paths=[\"root['sender']['phone_number']\", \"root['sender']['role']\"],\n",
    "        exclude_regex_paths=[\n",
    "            r\"root\\['recipients'\\]\\[\\d+\\]\\['phone_number'\\]\",\n",
    "            r\"root\\['recipients'\\]\\[\\d+\\]\\['role'\\]\",\n",
    "        ],\n",
    "        ignore_order=True,\n",
    "    )\n",
    "    return 1 - diff_result[\"deep_distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOTAL_EMAILS = 100\n",
    "N_TRAIN_EMAILS = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Similarly to my first project, we will use as data emails from the [Enron dataset](https://www.cs.cmu.edu/~enron/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz\"\n",
    "dataset_dir = Path(tempfile.gettempdir()) / \"llm_information_extraction\"\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "dataset_tar_file = dataset_dir / \"enron_mail_20150507.tar.gz\"\n",
    "dataset_extracted_dir = dataset_dir / \"enron_emails\"\n",
    "\n",
    "if not dataset_tar_file.is_file():\n",
    "    download(dataset_url, dataset_tar_file)\n",
    "\n",
    "shutil.rmtree(dataset_extracted_dir, ignore_errors=True)\n",
    "dataset_extracted_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with tarfile.open(dataset_tar_file, \"r:gz\") as tar:\n",
    "    already_visited_person = set()\n",
    "    for i, tarinfo in enumerate(tqdm(tar, desc=\"Tar archive files\")):\n",
    "        if len(already_visited_person) == N_TOTAL_EMAILS:\n",
    "            break\n",
    "        if not tarinfo.isfile():\n",
    "            continue\n",
    "        if \"inbox\" not in tarinfo.name:\n",
    "            continue\n",
    "        person_name = tarinfo.name.split(\"/\")[1]\n",
    "        if person_name in already_visited_person:\n",
    "            continue\n",
    "        already_visited_person.add(person_name)\n",
    "        tar.extract(tarinfo, dataset_extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_files = [x for x in dataset_extracted_dir.rglob(\"*\") if x.is_file()]\n",
    "\n",
    "email_parser = Parser(policy=default)\n",
    "parsed_emails: list[tuple[EmailMessage, dict[str, Any]]] = []\n",
    "\n",
    "for email_file in email_files:\n",
    "    with email_file.open() as f:\n",
    "        parsed_email = email_parser.parse(f)\n",
    "    parsed_email_dict = convert_email_to_dict(parsed_email)\n",
    "    parsed_emails.append((parsed_email, parsed_email_dict))\n",
    "\n",
    "train_set_indices = random.choices(range(0, N_TOTAL_EMAILS), k=N_TRAIN_EMAILS)\n",
    "test_set_indices = list(set(range(0, N_TOTAL_EMAILS)).difference(train_set_indices))\n",
    "train_set = [parsed_emails[i] for i in train_set_indices]\n",
    "test_set = [parsed_emails[i] for i in test_set_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_email, sample_email_dict = train_set[0]\n",
    "print(sample_email.as_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_email_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama.from_pretrained(\n",
    "    \"bartowski/Llama-3.2-1B-Instruct-GGUF\",\n",
    "    filename=\"Llama-3.2-1B-Instruct-Q8_0.gguf\",\n",
    "    n_ctx=16384,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_json_schema = {\n",
    "    \"type\": \"json_object\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"subject\": {\"type\": \"string\"},\n",
    "            \"sender\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"email\": {\"type\": \"string\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"phone_number\": {\"type\": \"string\"},\n",
    "                    \"role\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\"email\"],\n",
    "            },\n",
    "            \"recipients\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": [\n",
    "                    {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"type\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"to\", \"cc\", \"bcc\"],\n",
    "                            },\n",
    "                            \"email\": {\"type\": \"string\"},\n",
    "                            \"name\": {\"type\": \"string\"},\n",
    "                            \"phone_number\": {\"type\": \"string\"},\n",
    "                            \"role\": {\"type\": \"string\"},\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"email\",\n",
    "                            \"type\",\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"subject\", \"sender\", \"recipients\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant that outputs in JSON information extracted from an email provided by the user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": sample_email.as_string()},\n",
    "    ],\n",
    "    response_format=email_json_schema,\n",
    "    temperature=0.3,\n",
    ")\n",
    "extracted_information = json.loads(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "extracted_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_extracted_information_accuracy(extracted_information, sample_email_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "for parsed_email, parsed_email_dict in tqdm(test_set, desc=\"Emails\"):\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": parsed_email.as_string()},\n",
    "        ],\n",
    "        response_format=email_json_schema,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    extracted_information = json.loads(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "    accuracy = compute_extracted_information_accuracy(\n",
    "        extracted_information, parsed_email_dict\n",
    "    )\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "mean_accuracy = np.mean(accuracies).item()\n",
    "print(f\"Mean email information extraction accuracy: {mean_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Optimization\n",
    "\n",
    "As we have seen so far, the results are good but not great.\n",
    "\n",
    "We can improve that through prompt engineering but it's a tedious and manual process.\n",
    "\n",
    "We can instead use an optimizer to find a better prompt for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LlamaCpp(\n",
    "    model=\"llama\",\n",
    "    llama_model=llm,\n",
    "    model_type=\"chat\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailExtraction(dspy.Signature):\n",
    "    email: str = dspy.InputField(desc=\"Raw email content\")\n",
    "    subject: str = dspy.OutputField(desc=\"Email subject\")\n",
    "    sender: dict[str, str] = dspy.OutputField(\n",
    "        desc=\"Email sender's name, email address, phone number and role as a dictionary with keys 'email', 'name', 'phone_number', 'role'\",\n",
    "        examples=[{\"name\": \"John Smith\", \"email\": \"john.smith@enron.com\"}],\n",
    "    )\n",
    "    recipients: list[dict[str, str]] = dspy.OutputField(\n",
    "        desc=\"Email recipients' name, email address, phone number, role and type (to, cc, bcc) as a list of dictionaries with keys 'type', 'email', 'name', 'phone_number', 'role'\",\n",
    "        examples=[\n",
    "            [{\"name\": \"John Smith\", \"email\": \"john.smith@enron.com\", \"type\": \"to\"}]\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_extractor = dspy.ChainOfThought(EmailExtraction)\n",
    "email_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_correctness_metric(\n",
    "    example: dspy.Example, prediction: dspy.Prediction, trace=None\n",
    ") -> float:\n",
    "    example_dict = {\n",
    "        \"subject\": example[\"subject\"],\n",
    "        \"sender\": example[\"sender\"],\n",
    "        \"recipients\": example[\"recipients\"],\n",
    "    }\n",
    "    prediction_dict = {\n",
    "        \"subject\": prediction[\"subject\"],\n",
    "        \"sender\": prediction[\"sender\"],\n",
    "        \"recipients\": prediction[\"recipients\"],\n",
    "    }\n",
    "    return compute_extracted_information_accuracy(prediction_dict, example_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_examples = []\n",
    "for parsed_email, parsed_email_dict in train_set:\n",
    "    example = dspy.Example(\n",
    "        email=parsed_email.as_string(), **parsed_email_dict\n",
    "    ).with_inputs(\"email\")\n",
    "    train_set_examples.append(example)\n",
    "\n",
    "test_set_examples = []\n",
    "for parsed_email, parsed_email_dict in test_set:\n",
    "    example = dspy.Example(\n",
    "        email=parsed_email.as_string(), **parsed_email_dict\n",
    "    ).with_inputs(\"email\")\n",
    "    test_set_examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = email_extractor(email=test_set_examples[1].email)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_correctness = dspy.Evaluate(\n",
    "    devset=test_set_examples,\n",
    "    metric=extraction_correctness_metric,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_correctness(email_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mipro_optimizer = dspy.MIPROv2(\n",
    "    metric=extraction_correctness_metric,\n",
    "    auto=\"medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_email_extractor = mipro_optimizer.compile(\n",
    "    email_extractor,\n",
    "    trainset=train_set_examples,\n",
    "    max_bootstrapped_demos=3,\n",
    "    requires_permission_to_run=False,\n",
    "    minibatch=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_correctness(optimized_email_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this post, we have seen how to use a local LLM, using llama-cpp-python, to extract information from the raw content of emails and how to automatically improve the prompt by using dspy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_information_extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
